% !TEX root = manual.tex

\chapter{Applications and Skeletonization}
\label{sec:skeletonization}

\section{Basic Application porting}
\label{sec:skel:basic}
There are three parts to successfully taking a C++ code and turning it into a running application.
\begin{itemize}
\item Redirected linkage: Rather than linking to MPI, pThreads, or other parallel libraries (or even calling \inlinecode{hostname}), these functions must be redirected to \sstmacro rather than actually executing.
If you compiled with the \inlineshell{--enable-replacement-headers} flag, you get all redirected linkage for free by using
the SST compiler wrappers \inlineshell{sst++} and \inlineshell{sstcc} installed in the \inlineshell{bin} folder.
\item Skeletonization: While \sstmacro can run in emulation mode, executing your entire application exactly, this is not scalable.  To simulate at scale (i.e. 100K or more MPI ranks) you must strip down or ``skeletonize'' the application to the minimal amount of computation.  The energy and time cost of expensive compute kernels are then simulated via models rather than explicitly executed. 

\item Process encapsulation: Each virtual process being simulated is not an actual physical process. It is instead modeled as a lightweight user-space thread.  This means each virtual process has its own stack and register variables, but that is it.
Virtual processes share the same address space and the same global variables.  Some refactoring may be necessary if you have global variables.

\end{itemize}

\section{Redirected linkage}
\label{sec:skel:linkage}
As stated above, in contrast to previous versions, this is essentially automatic now if using the SST compiler wrappers.
The only minor wrinkle is potentially changing the application's entry point, i.e. \inlinecode{main}.
The SST/macro framework has already taken the \texttt{main} function, and consequently the user application becomes a sub-routine within the simulation environment. As introduced in Section~\ref{sec:tutorial:basicmpi}, one needs to change the entry function from \texttt{main} to \texttt{user\_skeleton\_main}, which has the same function signature as the \texttt{main} function.  This refactoring happens automatically in the SST compiler wrappers. 

If you need to use more than one application in the simulator at a time, you need multiple application entry points.
It is no longer possible to do automatic refactoring.  You must explicitly use the macro \inlinecode{sstmac_register_app}
and change the name of your \inlinecode{main}.  Thus, a code might look like

\begin{CppCode}
sstmac_register_app(my_app);

int my_app_main(int argc, char** argv)
{
...
\end{CppCode}
where the refactored \inlinecode{main} function matches the name of the declared application.


\section{Skeletonization}

A program skeleton is a simplified program derived from a parent application. The purpose of a skeleton application is to retain the performance characteristics of interest. At the same time, program logic that is orthogonal to performance properties is removed.  The rest of this chapter will talk about skeletonizing an MPI program, but the concepts mostly apply regardless of what programming/communication model you're using. 

The default method for skeletonizing an application is \textit{manually}. In other words, going through your application and removing all the computation that is not necessary to produce the same communication/parallel characteristics.   Essentially, what you're doing is visually backtracing variables in MPI calls to where they are created, and removing everything else.  

Skeletonization falls into three main categories:

\begin{itemize}
\item \textit{Data structures} - Memory is a precious commodity when running large simulations, so get rid of every memory allocation you can.
\item \textit{Loops} - Usually the main brunt of CPU time, so get rid of any loops that don't contain MPI calls or calculate variables needed in MPI calls.
\item \textit{Communication buffers} - While you can pass in real buffers with data to \sstmacro MPI calls and they will work like normal, it is relatively expensive. If they're not needed, get rid of them.
\end{itemize}

A decent example of skeletonization is HPCCG\_full (the original code) and HPCCG\_skel (the skeleton) in sstmacro/skeletons.  

\subsection{Basic compute modeling}

By default, even if you don't remove any computation, \textit{simulation time doesn't pass between MPI or other calls implemented by \sstmacro} unless you set

\begin{ViFile}
host_compute_modeling = true
\end{ViFile}

in your parameter file.  In this case, \sstmacro will use the wall time that the host takes to run code between MPI calls and use that as simulated time.  This only makes sense, of course, if you didn't do any skeletonization and the original code is all there. 

If you do skeletonize your application and remove computation, you need to replace it with a model of the time or resources necessary to perform that computation so that \sstmacro can advance simulation time properly. 
These functions are all accessible by using the SST compiler wrappers or by adding \inlinefile{#include <sstmac/compute.h>} to your file.

You can describe the time it takes to do computation by inserting calls to 

\begin{ViFile}
void sstmac_compute(double seconds)
\end{ViFile}
Usually, this would be parameterized by some value coming from the application, like loop size.   You can also describe memory movement with 

\begin{ViFile}
void sstmac_memread(long bytes);
void sstmac_memwrite(long bytes);
void sstmac_memcpy(long bytes);
\end{ViFile}
again usually parameterized by something like vector size.  
Using these two functions is the simplest and least flexible way of compute modeling.

\subsection{Detailed compute modeling}
The basic compute modeling is not very flexible.  
In particular, simply computing based on time does not account for congestion delays introduced by things like memory contention.
The highly recommended route is a more detailed compute model (but still very simple) that uses the operational intensity (essentially bytes/flops ratio) for a given compute kernel.
This informs \sstmacro how much stress a given code region puts on either the processor or the memory system.
If a kernel has a very high operational intensity, then the kernel is not memory-bound.
The means multiple threads can be running the kernel with essentially no memory contention.
If a kernel has a very low operational intensity, the kernel is memory bound.
A single thread will have good performance, but multiple threads will compete heavily for memory bandwidth.
If a kernel has a medium operational intensity, a few concurrent threads may be possible without heavy contention, 
but as more threads are added the contention will quickly increase.

The function prototype is

\begin{CppCode}
void
sstmac_compute_detailed(long nflops, long nintops, long bytes);
\end{CppCode}
Here \inlinecode{flops} is the number of floating point operations and \inlinecode{bytes} is the number of bytes that hit the memory controller.
\inlinecode{bytes} is \emph{not} simply the number of writes/reads that a kernel performs.
This is the number of writes/reads that \emph{miss the cache} and hit the memory system.
For now, \sstmacro assumes a single-level cache and does not distinguish between L1, L2, or L3 cache misses.
Future versions may incorporate some estimates of cache hierarchies.
However, given the coarse-grained nature of the simulation, explicit simulation of cache hierarchies is not likely to provide enough improved accuracy or physical insight to justify the increased computational cost. 
Additional improvements are likely to involve adding parameters for pipelining and prefetching.
This is currently the most active area of \sstmacro development.

The characterization of a compute kernel must occur outside \sstmacro using performance analysis tools like Vtune or PAPI.
For the number of flops, it can be quite easy to just count the number of flops by hand.
The number of bytes is much harder.
For simple kernels like a dot product or certain types of stencil computation, 
it may be possible to pen-and-paper derive estimates of the number of bytes read/written from memory since every read is essentially a cache miss.
In the same way, certain kernels that use small blocks (dense linear algebra), it may be possible to reason \textit{a priori} about the cache behavior.
For more complicated kernels, performance metrics might be the only way.
Further discussion and analysis of operational intensity and roofline models can be found in ``Roofline Model Toolkit: A Practical Tool for Architectural and Program Analysis'' by Yung Ju Lo et al.  The PDF is available at \url{http://www.dcs.warwick.ac.uk/~sdh/pmbs14/PMBS14/Workshop_Schedule.html}.

\subsection{Skeletonization Issues}

The main issue that arises during skeletonization is data-dependent communication.  In many cases, it will seem like you can't remove computation or memory allocation because MPI calls depend somehow on that data.  The following are some examples of how we deal with those:

\begin{itemize}
\item \textit{Loop convergence} - In some algorithms, the number of times you iterate through the main loop depends on an error converging to near zero, or some other converging mechanism.  This basically means you can't take out anything at all, because the final result of the computation dictates the number of loops.  In this case, we usually set the number of main loop iterations to a fixed (parameterized) number.  Do we really care exactly how many loops we went through?  Most of the time, no, it's enough just to produce the behavior of the application.  
\item \textit{Particle migration} - Some codes have a particle-in-cell structure, where the spatial domain is decomposed among processes, and particles or elements are distributed among them, and forces between particles are calculated.  When a particle moves to another domain/process (because it's moving through space), this usually requires communication that is different from the force calculation, and thus depends entirely on the data in the application.  We can handle this in two ways:
\begin{enumerate}
\item \textit{Ignore it} - If it doesn't happen that often, maybe it's not significant anyway.  So just remove the communication, recognizing that the behavior of the skeleton will not be fully reproduced.
\item \textit{Approximate it} - If all we need to know is that this migration/communication happens sometimes, then we can just make it happen every so many iterations, or even sample from a probability distribution.  
\end{enumerate}
\item \textit{AMR} - Some applications, like adaptive mesh refinement (AMR), exhibit communication that is entirely dependent on the computation.  In this case, skeletonization is basically impossible, so you're left with the following options:
\begin{itemize}
\item \textit{Traces}  - revert to DUMPI traces, where you will be limited by existing machine size.  Trace extrapolation is also an option here.
\item \textit{Run it} - get yourself a few servers with a lot of memory, and run the whole code in \sstmacro.
\item \textit{Synthetic} - It may be possible to replace communication with randomly-generated data and decisions, which emulate how the original application worked. This hasn't been tried yet.
\item \textit{Hybrid} - It is possible to construct meta-traces that describe the problem from a real run, and read them into \sstmacro to reconstruct the communication that happens.  Future versions of this manual will have more detailed descriptions as we formalize this process.
\end{itemize}
\end{itemize}

\section{Process Encapsulation}

As mentioned above, virtual processes are not real, physical processes inside the OS.
They are explicitly managed user-space threads with a private stack, but without a private set of global variables.
When porting an application to SST/macro, global variables used in C programs will not be mapped to separate memory addresses causing incorrect execution or even segmentation faults.
If you have avoided global variables, there is no major issue.  
If you have read-only global variables with the same value on each machine, there is still no issue.
If you have mutable global variables or read-only variables such as \inlinecode{mpi_rank} that differ across processes,
there is so minor refactoring that needs to be done.

\subsection{Manually refactoring global variables}
\label{sec:skel:globals}
\sstmacro provides a complete set of global variable replacements from 
\inlinecode{\#include <sstmac/sstmac\_global.h>}, which is automatically included the SST compiler wrappers.
Then replace the variable type declaration with the ones that have a \inlinecode{global\_} prefix in the header file.
To use this file, you must compile your application with a C++ compiler as a C++ program.  While most of C++ is backwards-compatible, there are some things that are not, and will require either a compiler flag to relax strictness or quick refactor of some of your syntax.

When printing a global variable with \inlinecode{printf}, the user should explicitly invoke a cast to the primitive type in the function call:

\begin{CppCode}
print("Hello world on rank %d", int(rank));
\end{CppCode}
If not explicitly cast, the \inlinecode{va\_args} function will be misinterpreted and produce an ``Illegal instruction" error.  
This still follows the ``single-source'' principle since whether compiling for \sstmacro or a real machine, the code is still valid.

\subsection{Automatically refactoring global variables}
Tools are currently in use by developers to automatically refactor codes to use no global variables.
This involves running the source code through a compiler tool chain that then creates a \inlinecode{struct}
encapsulating all global variables into thread-specific classes.
This process is only for advanced users and requires developer help.

%\section{Eiger}
%
%The most flexible, but most complex, method for modeling computation is to use the Eiger Statistical Modeling framework to generate performance models that are polled at runtime. These models take as parameters application-level metrics and map them to performance based on statistical models generated from instrumentation data collected off-line from simulation with SST/macro. These models are generated based off empirical data; patterns about the effect variations in the input values have on performance appear as the sample size grows. This means that by collecting instrumentation data for a large range of application problem sizes, the models are capable of extrapolating performance as problem size grows. Typically the input metrics for these models are any values that may have a direct or indirect effect on the performance of the application. For example, it would be safe to assume that the matrix sizes for a matrix multiplication kernel would correlate with execution time, and therefore would be a good candidate for inclusion in instrumentation. The Eiger framework is robust to handling large sets of input metrics, so the rule of thumb is to be liberal when deciding what to include.
%
%The method for polling Eiger models is through
%\begin{ViFile}
%void SSTMAC_compute_eiger(std::map<std::string, double> values, std::string model_name)
%\end{ViFile}
%The \textit{values} parameter maps metric names to their associated values to poll the model \textit{model\_name}. We also provide convenience functions
%\begin{ViFile}
%void SSTMAC_compute_eiger1(std::string model_name, std::string prefix, 
%                           std::string name1, double val1);
%void SSTMAC_compute_eiger2(std::string model_name, std::string prefix, 
%                           std::string name1, double val1, std::string name2, double val2);
%void SSTMAC_compute_eiger3(std::string model_name, std::string prefix, 
%                           std::string name1, double val1, std::string name2, double val2,
%                           std::string name3, double val3);
%\end{ViFile}
%and so on up to 7. For these versions, the \textit{prefix} parameter allows annotating a prefix to the file name containing the model.
%
%Example usage of Eiger in a skeleton is minimd-cpu, found in sstmacro/skeletons.
%
%Please visit \url{https://bitbucket.org/eanger/eiger} for more information on getting, installing, and using Eiger to generate models, as well as methodology for adding instrumentation to your code.
%
%
%
%
%
%\section{Semi-Automatic Skeletonization}
%\label{sec:skel:method}
%
%\noindent The skeletonization process described here is an iterative process to generate a program skeleton from source code. The skeleton extraction process consists of several sub-processes:
%
%\begin{enumerate}
%\item Static code analysis.
%\item User guidance to augment analysis.
%\item API Specification of skeletonization target characteristics.
%\item Code transformation and generation.
%\end{enumerate}
%
%\subsection{Building the Auto-skeletonizer}
%The latest version of the auto-skeletonizer is shipped as part of the ROSE compiler project. It will be build automatically when building the ROSE compiler from source, which can be obtained from GitHub:
%
%\begin{ShellCmd}
%$ git co https://github.com/rose-compiler/edg4x-rose.git
%\end{ShellCmd}
%For detailed instructions on how to build the ROSE compiler, please refer to the ROSE documentation on:\\\url{http://rosecompiler.org/}.
%If an old version of ROSE installation is avaible to your enviroment, the auto-skeletonizer might also be build separeately using the existing ROSE installation.
%First, obtain the source code of the stand alone auto-skeletonizer using git:
%
%\begin{ShellCmd}
%$ git co https://github.com/mjsottile/rose-mpi-skeletons.git rose-mpi-skeletons
%\end{ShellCmd}
%Then modify the makefile inside the \texttt{rose-mpi-skeletons} folder making it pointing to the existing ROSE installation. Edit the first two lines of the makefile as follows:
%
%\begin{ViFile}
%ROSEINSTALL=/path/to/your/rose/installation/dir/
%BOOSTINTALL=/path/to/your/boost/installation/dir/
%\end{ViFile}
%Last, building the executables with the default makefile:
%
%\begin{ShellCmd}
%$ make
%\end{ShellCmd}
%A successful build using either approach should give your three executables: extractMPISkeleton, generateSignatures, and summarizeSignatures. The use of these executables to generate skeleton source code is explained in the following section.
%
%\subsection{Static Analysis}
%
%\noindent In the static analysis phase, the compilation analysis is performed in three parts:
%
%\begin{enumerate}
%
%\item[1.1] Generating summary information for each function in a given compilation unit.
%
%\item[1.2] Combining individual summary files into a larger summary of the program.
%
%\item[1.3] Extraction of the MPI skeleton using the combined summary information.
%
%\end{enumerate}
%
%\noindent In 1.1, in order to generate the summary information of a source program, we can invoke the following tool:
%
%\begin{ShellCmd}
%$  generateSignatures [options] file...
%\end{ShellCmd}
%
%\noindent The command-line options are as follows:
%
%\begin{CppCode}
% -signature:(o|output) filename - Use 'filename' as the output.
% -signature:(d|debug)           - Print debugging messages.
%\end{CppCode}
%
%\noindent In 1.2, we can combine several compilation units from 1.1 to generate a combined signature by invoking the following tool: 
%
%\begin{ShellCmd}
%$  summarizeSignatures [options] <signature files>
%\end{ShellCmd}
%
%\noindent The command-line options are as follows:
%
%\begin{CppCode}
% -summarize:(o|output) filename - Use 'filename' as the output.
% -summarize:(s|spec) filename   - Use 'filename' as API specification.
% -summarize:(d|debug)           - Print debugging messages.
%\end{CppCode}
%
%\noindent The last two options are only needed for debugging.
%
%\noindent The user should specify all the signature files from the previous step of the analysis in a single step. While the generation of the summary is additive, the overall analysis is more efficient if performed in a single step. \\
%
%\noindent In 1.3, the user can extract the program skeleton using the summarized signature file from 1.2 by invoking the following tool: 
%
%\begin{ShellCmd}
%$  extractMPISkeleton [options] file...
%\end{ShellCmd}
%
%\noindent The filenames are skeletonized and the output is written to files with `rose ' prepended to the filenames. \\
%
%\noindent The command line options are these: 
%
%\begin{CppCode}
% -skel:(o|outline)       - Outline everything not in the skeleton.                   
% -skel:(s|spec) filename - Use 'filename' as the specification of the API.
% -skel:(g|sig)  filename - Use 'filename' as the summary information.
% -skel:(d|debug)         - Print debugging messages.
% -skel:(p|pdf)           - Generate PDF of the generated AST.
%\end{CppCode}
%
%\noindent The last two options are only needed for debugging. In order for the analysis to be complete, a signature file generated from the summarizeSignatures tool must be provided.\\
%
%\noindent Current limitations:
%\noindent The skeleton generator supports C and C++ only. Fortran is not supported with this version of the program skeletonization tool.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\subsection{User guidance to augment analysis}
%
%In this phase, users can annotate the program skeleton file to augment the code analysis. \\
%
%\noindent Annotations used by this tool are specified in the following format:
%
%\begin{CppCode}
%#pragma skel [specific pragma text here]
%\end{CppCode}
%
%\noindent Currently, three types of data annotation are supported:
%
%\subsubsection{Loop annotations}
%
%It is not uncommon for skeletonized code to no longer have the looping behavior of the parent application. 
%
%To fix any problems stemming from the modified loop behavior, three options for loop annotations are available:
%
%\begin{CppCode}
%#pragma skel loop iterate exactly(n)
%#pragma skel loop iterate atmost(n)
%#pragma skel loop iterate atleast(n)
%\end{CppCode}
%
%These options correspond to forcing an exact, upper, and lower bound on the iteration count. The pragma must be placed immediately preceding the loop of interest. Loops constructed with 'for', 'while', or 'do while' are all supported as well as loops containing break and continue statements.
%
%\subsubsection{Data declaration annotations}
%
%If a program contains an array that should be preserved in the skeleton, it is useful to have control over how it is initialized since often the skeleton will not contain the computation code that populates the array elements.  The initializer pragma allows these element values to be specified.
%
%\begin{CppCode}
%#pragma skel initializer repeat(x)
%int myArray[14];
%\end{CppCode}
%
%(Where 'x' is a C-expression interpreted in the current scope of the program.)
%
%\subsubsection{Conditional statement annotations}
%
%The conditional annotation currently allows programmers to experiment with skeletons that will randomly branch one way or the other with a specified probability.
%
%The general case is:
%
%\begin{CppCode}
%#pragma skel condition prob(p)
%\end{CppCode}
%
%(Where 'p' is a C-expression interpreted in the current scope of the program
%which should be a floating point number between 0 and 1.0.  As noted above,
%floating point constants are not allowed due to current limitations of
%ROSE.)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%\subsection{API Specification of skeletonization points}
%
%The skeleton generator skeletonizes programs relative to one or more API specifications. 
%
%\noindent APIs are specified in a configuration file that uses an s-expression format. Each API call is a sub-expression with the format:
%
%\begin{CppCode}
%(API_FUNCTION_NAME ARGUMENT_COUNT (deptype argA ..) (deptype argB ..) ...)
%\end{CppCode}
%
%The API collection file is specified using the -skel:s
%command line option:
%
%\begin{ShellCmd}
%$ extractMPISkeleton -skel:s /where/is/the/collection/file
%\end{ShellCmd}
%
%\subsection{Outlining}
%
%The skeleton generator can work in an alternate mode, Outlining.  This mode is specified with the following command-line option:
%
%\begin{CppCode}
%  -skel:o
%  -skel:outline
%\end{CppCode}
%
%In this mode, rather than removing the non-skeleton code, the tool will "outline" (move into separate functions, the converse of inlining) all non-skeleton code.
%
%\subsection{Skeleton Behavior Validation}
%\label{sec:skel:validation}
%Skeleton correctness is important in studying the scalability of an application using the skeleton-driven approach. Based on the trace files produced by the DUMPI library in Section~\ref{sec:tutorial:dumpi}, the trace analysis tool creates a statistical report of various metrics and characteristics of the program skeleton.
%
%The trace analysis tool is built as part of the SST/macro package and can be found in the installation directory. The following command will invoke the trace analysis tool on an existing trace file:
%\begin{ShellCmd}
%$ <SSTMAC_INSTALL>/bin/traceanalyzer -v -o report.xml dumpitracer.meta
%\end{ShellCmd}
%A XML report file will be generated after the analyzing process is done. When comparing the report file with one generated from the original applicaiton, the MPI message and traffic count can be used to verify if the desired communication behavior is preserved.
