%% !TEX root = manual.tex

\section{SST/macro Parameter files}
\label{sec:parameters}
A minimal parameter file setting up a 2D-torus topology is shown below. 
This is meant to be run with the executable compiled in \inlineshell{tutorials/sendrecv\_cxx}.

\begin{ViFile}
# Launch parameters
launch_indexing = block
launch_allocation = first_available
launch_app1_cmd = aprun -n2 -N1
launch_app1 = user_mpiapp_cxx
launch_app1_argv = 
# Network parameters
network_name = simple
network_bandwidth = 1.0GB/s
network_hop_latency = 100ns
# Topology - Ring of 4 nodes
topology_name = hdtorus
topology_geometry = 4,4
# Node parameters
node_cores = 1
node_name = null
node_memory_model = null
nic_name = null
# Application parameters
sendrecv_message_size = 128
\end{ViFile}
The input file follows a basic syntax of \inlinefile{parameter = value}.  
Parameter names follow C++ variable rules (letters, numbers, underscore) while parameter values can contain spaces.  Trailing and leading whitespaces are stripped from parameters.
Comments can be included on lines starting with \#.

The input file is broken into sections via comments.  
First, application launch parameters must be chosen determining what application will launch, 
how nodes will be allocated, how ranks will be indexed, and finally what application will be run.  
Additionally, you must specify how many processes to launch and how many to spawn per node.  
We currently recommend using aprun syntax (the launcher for Cray machines), 
although support is being added for other process management systems.
\sstmacro can simulate command line parameters by giving a value for \inlinefile{launch_app1_argv}.

A network must also be chosen.  
In the simplest possible case, the network is modeled via a simple latency/bandwidth formula.  
For more complicated network models, many more than two parameters will be required. 
See \ref{sec:tutorial:networkmodel} for a brief explanation of \sstmacro network congestion models. 
A topology is also needed for constructing the network.  
In this case we choose a 2-D 4$\times$4 torus (16 switches).  The \inlinefile{topology_geometry} 
parameter takes an arbitrarily long list of numbers as the dimensions to the torus.

Finally, we must construct a node model.  
In this case, again, we use the simplest possible models (null model) for the node, 
network interface controller (NIC), and memory.  
The null model is essentially a no-op, generating the correct control flow but not actually simulating any computation. 
This is useful for validating program correctness or examining questions only related to the network.  
More accurate (and complicated) models will require parameters for node frequency, memory bandwidth, injection latency, etc.

Parameter files can be constructed in a more modular way through the \inlinefile{include} statement.  
An alternative parameter file would be:

\begin{ViFile}
include machine.ini
# Launch parameters
launch_indexing = block
launch_allocation = first_available
launch_app1_cmd = aprun -n2 -N1
launch_app1 = user_mpiapp_cxx
launch_app1_argv = 
# Application parameters
sendrecv_message_size = 128
\end{ViFile}
where in the first line we include the file \inlinefile{machine.ini}.  
All network, topology, and node parameters would be placed into a \inlinefile{machine.ini} file.  
In this way, multiple experiments can be linked to a common machine.  
Alternatively, multiple machines could be linked to the same application by creating and including an \inlinefile{application.ini}.

Another feature of input files it the ability to use variables.
For example, you may wish to have several components all with identical bandwidth.
Values can be linked to an input variable through \inlinefile{set var}.

\begin{ViFile}
set var mybw = 1.0GB/s
network_bandwidth = $mybw
memory_bandwidth = $mybw
\end{ViFile}
The bandwidths can now be tuned through a single variable.


%\subsection{Parameter Sweeping with fork()}
%\label{sec:parameters:multi}
%
%Often, an experiment consists of sweeping one or more parameters and observing the effect on performance.  This 
%can be accomplished by specifying a set of parameter values in brackets, separated by $|$, like so:
%
%\begin{ViFile}
%...
%sendrecv_message_size = {128|256|512|1024}
%multisim_nproc = 2
%\end{ViFile}
%
%\sstmacro will automatically fork to run each configuration separately, and a file for each configuration will be created with the simulator output.  The \inlinefile{multisim_nproc} parameter controls how many simulations will be run concurrently.   If multiple parameters specify ranges, then
%\sstmacro will run every permutation of them.   Sometimes only a subset of all permutations is desired, so to address this you can also apply this mechanism to the \inlinefile{include} directive, like so:
%
%\begin{ViFile}
%include {machine1.ini | machine2.ini}
%...
%sendrecv_message_size = {128|256|512|1024}
%multisim_nproc = 10
%\end{ViFile}
%
%Note that an \textit{included} parameter file can also have parameter ranges, but this can get out of hand quickly keeping track of everything, so we recommend sticking to the above methods.
%
%The simulator will number each configuration and print this numbering before it starts anything, and ask you to hit enter to continue.    If you want to run a single configuration, usually for debugging without having to change the parameter file,
%you can specify the -r [number] command line option to run just that configuration.

%%\subsection{Parameter Sweeping with MPI}
%%\label{sec:parameters:mpisweep}
%%
%%\sstmacro also has the ability to use the above format for parameter sweeping, but use a cluster and MPI to do the parallel simulations.  Just configure \sstmacro with `--enable-mpiparallel', like you would for enabling parallel discrete event simulation (see Section \ref{sec:PDES}), and a binary will be built at \inlinefile{bin/sstmac-mpisweep}.  Just launch this program like you would any MPI program.
