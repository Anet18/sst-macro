% !TEX root = developer.tex

\newcommand{\evhandler}{\inlinecode{event_handler}\xspace}
\newcommand{\evscheduler}{\inlinecode{event_scheduler}\xspace}
\newcommand{\evmgr}{\inlinecode{event_manager}\xspace}

\chapter{Discrete Event Simulation}
\label{chapter:des}
There are abundant tutorials on discrete event simulation around the web.
To understand the basic control flow of \sstmacro simulations,
you should consult Section 3.6, Discrete Event Simulation, in the user's manual.
For here, it suffices to simply understand that objects schedule events to run at a specific time.
When an event runs, it can create new events in the future.
A simulation driver gradually progresses time, running events when their time stamp is reached.
As discussed in the user's manual, we must be careful in the vocabulary.
\emph{Simulation time} or \emph{simulated time} is the predicted time discrete events are happening in the simulated hardware.
\emph{Wall time} or {wall clock time} is the time \sstmacro itself has been running.
There are a variety of classes the cooperate in driving the simulation, which we now describe.

\section{Event Managers}
The driver for simulations is an event manager that provides the function

\begin{CppCode}
virtual void
schedule(timestamp start_time, event* event) = 0;
\end{CppCode}
This function must receive events and order them according to timestamp.
Two main types of data structures can be used, which we briefly describe below.

The event manager also needs to provide

\begin{CppCode}
virtual void
run() = 0;
\end{CppCode}

The termination condition can be:
\begin{itemize}
\item A termination timestamp is passed.  For example, a simulation might be specified to terminate after 100 simulation seconds. 
Any pending events after 100 seconds are ignored and the simulation exits.
\item The simulation runs out of events.  With nothing left to do, the simulation exits.
\end{itemize}

Event objects are an abstract class

\begin{CppCode}
namespace sstmac {

class event
{
 public:
  virtual void
  execute() = 0;

  virtual event_loc_id
  event_location() const = 0;
};
\end{CppCode}

The execute function is invoked by the \evmgr to run the underlying event.
Every event must identify its location via the \inlinecode{event_loc_id} struct.
There are generally two basic event types in \sstmacro, which we now introduce.

\subsection{Event Handlers}
In most cases, the event is represented as a message sent to an object called an \evhandler at a specific simulation time.
In handling the message, the event handlers change their internal state and may cause more events
by scheduling new messages at other event handlers (or scheduling messages to itself) at a future time.
The workhorses for \sstmacro are therefore classes that inherit from \evhandler.
The only method that must be implemented is

\begin{CppCode}
void
handle(sst_message* msg);
\end{CppCode}
The function is the common interface for numerous different operations from network injection to memory access to MPI operations.
In general, objects have two ``directions'' for the action - send or receive.
A NIC could ``handle'' a message by injecting it into the network or ``handle'' a message by reporting up the network stack the message has arrived.
In most cases, the handled message must therefore carry with it some notion of directionality or final destination.
An event handler will therefore either process the message and delete the message, or, if that handler is not the final destination, forward it along.
Some event handlers will only ever receive, such as a handler representing a blocking $MPI_Recv$ call.
Some event handlers will always receive and then send, such as network switches who are always intermediate steps between the start and endpoints of a network message.

In most cases, events are created by calling the function

\begin{CppCode}
void
schedule(const timestamp &t,
  event_handler* handler,
  sst_message* msg);
\end{CppCode}

This then creates a class of type \inlinecode{handler_event}, for which the execute function is

\begin{CppCode}
void
handler_event::execute()
{
  if (!canceled_) {
    handler_->handle(msg_to_deliver_);
  }
}
\end{CppCode}

\subsection{Arbitrary Events}
In some cases, it can be inconvenient (and inefficient) to require every event to be funneled through an \evhandler type.
A generic macro for creating events from any class member function is provided in the file \inlineshell{event_callback.h}.
For example, the MPI server creates an event

\begin{CppCode}
mpi_queue_recv_request* req = next_request();
event* ev = new_event(this, &mpi_queue::start_recv, req);
\end{CppCode}
The new event macro takes as first argument an object and second argument a member function pointer to be invoked when the event is run.
The remaining arguments are an arbitrary-length list of inputs of any type - they don't need to be messages. 
These inputs should match the member function prototype. 
For example, the prototype

\begin{CppCode}
void
mpi_queue::start_recv(mpi_queue_recv_request* req)
{
  ...
}
\end{CppCode}
takes a single \inlinecode{recv_request} object as input.
This eases the programming burden in two ways.
First, it avoids having to always create \evhandler types.
Without template events, you would have to create a new class the inherits from \evhandler that performs a single, desired action.
Second, it helps direct messages to the right place.  A single \evhandler might process many different types of messages or objects.
If every message went to a single \inlinecode{handle} method, the handle method would need either a long if-else block or switch to sort messages.
The message would also need to be dynamic cast to the correct type.
By creating event functors, the message can be immediately directed to the correct type and correct action.

For generic events, one must ensure the event is scheduled to the same node and does not cross any network boundaries.
Generic events are not compatible with parallel simulation.
The event created must be run on the same logical process.

\subsection{Event Heap/Map}
The major distinction between different event containers is the data structured used.
The simplest data structure is an event heap or ordered event map.
The event manager needs to always be processing the minimum event time, which maps naturally onto a min-heap structure.
Insertion and removal are therefore log(N) operations where N is the number of currently scheduled events.
In some cases where many short events are created, the log(N) overhead can actually become very expensive.
The simulation may spend $\tfrac{1}{3}$ or $\tfrac{1}{2}$ of it's time just scheduling and ordering events.
For most cases, the number and length of events is such that the min-heap is fine.

\subsection{Event Calendar}
For certain pathological cases, O(1) event scheduling and event processing is highly desirable.
Rather than using a tree or heap to sort events, an array of bins (an event calendar) can be created.
Based on the timestamp, an event is directly mapped to its corresponding bin.
The array access is O(1).
The price you pay is potentially needing a very large array to store the event calendar.

\section{Event Schedulers}
The simulation is partitioned into objects that are capable of scheduling events.
Many \evscheduler objects are also \evhandler objects.
Common examples of \evscheduler objects are nodes, NICs, memory systems, or the operating system.
In serial runs, an event scheduler is essentially just a wrapper for the \evmgr and the class is not strictly necessary.
In parallel simulation, though, the simulation must be partitioned into different scheduling units.
Scheduling units are then distributed amongst the parallel processes.
The \evscheduler is therefore the basic unit of parallelism.
Additionally, when simulating failures (in either serial or parallel), certain devices must be deactivated such as a node or network switch going down.
This basically amounts to canceling all events associated with a given \evscheduler.
The \evscheduler is therefore primarily a means of structuring the computation.



